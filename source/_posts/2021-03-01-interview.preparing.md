---
layout: post
title:  "Interview Preparing"
date:   2021-03-01 00:0054 +0900
categories: java
---

## 1. Dead Lock (교착상태)

두 A, B 프로세스가 한 공유될 수 있는 자원을 바라보고 있다고 하자. 만약 A 프로세스가 이 자원을 선점하고 있고 A 프로세스는 B 자원이 이 자원을 선점해야 이 자원 선점을 해지할 수 있다. 또 B 프로세스는 이 공유되는 자원을 선점해야 다음 작업이 진행이 가능하다.

이런 경우 두 프로세스의 진행이 불가능 하기 때문에 교착상태, dead lock 이라고 표현한다.

이론적으로 교착상태는 아래의 조건이 모두 성립해야 발생한다.

상호배제, 점유대기, 비선점, 순환대기.




## 2. Transaction

### 트랜잭션 정의

데이터 정합성을 유지하기 위해 정해놓은 최소한의 논리적 작업 단위.

### RDB DBMS의 트랜잭션 관리

DBMS는 기본적으로 질의 처리기와 저장 시스템 두 부분으로 나누어진다.

그리고 저장 시스템에 메인 메모리에 유지하는 페이지들을 관리하는 페이지 버퍼라는 모듈이있다.
이 페이지 버퍼라는 모듈이 트랜잭션 관점에서 굉장히 중요하다.

수행한 질의에 대해서 커밋을 하지 않았다면 이 버퍼에 수정 내용들이 존재하는데. 이를 활용해서 롤백을 할 수 있다.

하나의 트랜잭션에서 오류가 발생할 경우 데이터 정합성을 맞추기 위해 롤백이 필요하다.

### Mybatis 같은 SQLMapper 에서의 트랜잭션 관리.

java에서 RDB 접근할때에는 JDBC API를 주로 사용한다. 이 API 기본적으로 질의를 했을 때 해당 내용을 auto commit하는 옵션이 true로 되어있다.  왜 그렇게 되어있을까. 왜 이렇게 되어있어서 트랜잭션 관리를 하기 어렵게 만들었을까... 그건 나도 모르지 그렇기 때문에 위 버퍼를 활용하기 어렵고 롤백시키가 까다롭다.

해결할 수 있는 방법 중 하나는 쿼리 자체를 한번에 하도록 하는 것 쿼리 한번에 커밋이 되니까 한번의 쿼리에 데이터 정합성이 맞게 모두 처리하는 방법

해결할 수 있는 두번째 방법은 auto commit 옵션을 해지하기.

세번째 방법 @Transactional 어노테이션 적용.

### JDBC 트랜잭션 유지 방법

JDBC API를 사용할 때 트랜잭션 유지 방법

1. cath 블록에서 rollback 작업 명시

2.  DatasourceTransactionManager

3. @Transactional 

### JPA 에서의 트랜잭션 관리.

Persistent Context 에서 애초에 커밋을 바로 하지 않고 트랜잭션이 완료되었을 때 리얼 DB에 커밋을 함.
그렇기 때문에 한 트랜잭션 내에서 오류가 발생하면 아에 DB에 넣은 내용이 없기 때문에 롤백 처리가 간단함.






## 3. MyISAM, InnoDB -> 이거는 MySQL 얘기네

MyISAM 엔진은 SQL 명령한번에 바로 데이터가 commit(승인)이 돼서 rollback(되돌리기)을 할 수 가없어요.





## 4. Spring IoC (Inversion Of Control)

객체의 생성이나 의존성 주입에 대한 관리 주체를 개발자가 가지는게 아니라 프레임워크, 컨테이너가 가지는 개념이다. 

기존에는 개발자가 했었는데 이 책임을 프레임워크가 가져갔다 해서 IoC 라고 부른다.

의존성 관리라는 것이 커지면 커질수록 개발자에게는 부담이 되는 요소인데 이를 스프링의 경우 스프링 컨테이너에 빈등록을 하고 바로바로 의존성을 주입할 수 있도록 도와준다.





## 5. MVC (Model View Controller)

### 정의

Model, View, Controller 세가지 영역으로 나누어서 개발하는 방법. Model은 데이터를 담당하고 View는 화면을 담당합니다. 이 둘사이에서 조건에 따른 처리달라지거나 제어의 목적으로 사용되는 것이 Controller 영역입니다. Spring Framework로 Web MVC를 구현했을 때 JSP, Thymeleaf는 View 영역에 해당하고, Model, Service 쪽은 Model 영역에 해당합니다. Spring Controller가 MVC에서 Controller 영역에 해당합니다.

### 장점

1. 각 영역이 담당하는 업무 주제가 날카로워지기 때문에 분업의 효과를 가져올 수 있다.

2. 코드들이 분리가 되기 때문에 상호간 의존성이 감소해서 어플리케이션의 유연성과 확장성을 증가시킬 수 있습니다.

3. 각 영역이 담당하는 업무가 확실해지기 때문에 디버깅하기가 쉬워진다. 예를 들어 팝업이 안뜨는 오류가 발생했다면 이 오류는 View 영역의 오류일 것입니다.





## 6. 웹서버

### 정의

HTTP 프로토콜 기반의 요청을 받아들이고 그 요청에서 원하는 HTML 문서, 이와 관련된 데이터를 반환해주는 프로그램.

### 구현 방법

#### MPM (Multi Processing Module)

##### prefork (process)

각 요청을 프로세스로 받아서 처리한다. 각 요청에 따라 다른 프로세스를 사용하기 때문에 사용되는 메모리도 독립적이며, 다른 요청들에게 영향을 주지 않는다.
매번 PCB를 새로 생성하기 때문에 자원을 많이 사용하게 된다.

멀티 프로세스 방식 마스터 프로세스가 있고 요청이 들어오면 슬레이브 프로세스를 fork 하여 만들고 이 슬레이브 프로세스에서 요청에 대한 처리를 한다.

매 요청에 맞춰서 슬레이브 프로세스를 만들어야 하기때문에 프로세스가 계속 늘어나는 문제점과, 매번 요청에 따라서 슬레이브 프로세스로 바꾸는 context switching 비용이 있다.

##### worker (thread)

각 요청을 스레드로 받아 처리한다. 

프로세별로 제한하는 스레드 개수 만큼 스레드를 생성하며 이를 초과하게 되면 새로운 프로세스를 생성하여 처리.

쓰레드 기반이기 때문에 프로세스 기반인 prefork 보다는 리소스 부하가 적다.

매번 쓰레드를 생성하는 비용은 쓰레드 풀을 만들어서 해결할 수 있다고 해도, 쓰레드끼리의 문맥교환 비용이 존재함.

worker 방법이 prefork 방법에 비해 고속처리, 대량처리가 가능한 것은 아니지만 리소스 부하를 줄일 수 있다.

##### event

nginx 에 대응하기 위해서 apache 에서 event-driven 구조를 지원하도록 업데이트함.

#### Event-driven





## 7. WAS

### 정의

기존의 웹서버 기능에 Servlet Container가 포함된 프로그램.
동적 컨텐츠를 제공할 수 있다.

서버의 비즈니스 로직을 실행하여 해당 결과물을 요청 객체에게 반환해주는 프로그램

### 웹서버와 WAS를 병행해서 사용하는 이유

1. 2티어 구조로 변경함으로써 각자 역할에 대해서 응집도를 높이고 Loose Coupling. 디버깅도 하기 쉬워진다.


2. 성능 향상 - 각자의 서버의 관심사가 몰입되기 때문에 캐시 적중률이 높아질 것 같습니다.

3. 웹서버 1대 WAS 여러 대를 둘때 로드밸런싱을 해주는 역할이 웹서버.

4. 웹서버만 대외적으로 드러나고 이 웹서버를 통해서 WAS를 접근하게 됨으로 보안이 강화된다. WAS에서는 대부분 DB를 접속하는 기능도 포함되어 있기 때문에 노출시키지 않는 것이 좋다.


### 웹서버에서 WAS까지 데이터 흐름 이해하기

톰캣은 apache의 웹서버의 역할도 가지고 있기 때문에 내부적으로는 웹서버 + 서블릿 컨테이너로 구분된다고 할 수 있다.

웹서버가 처리할 수 없는 동적 컨텐츠에 대한 요청이 들어오면 서블릿 컨테이너에서 이 요청을 처리하기 위한 서블릿을 생성한다.

실제로 DispatcherServlet 이 녀석은 Servlet 인터페이스를 구현한 객체이다. 그래서 스프링을 띄우고 있는 WAS라면 Servlet Container에서 DispatcherServlet을 실행한다.

DispatcherServlet은 요청 데이터와 mapping되는 컨트롤러를 찾고 연결한다. 서버쪽의 비지니스 로직 처리가 완료되면 해당 결과물을 ViewResolver를 통해 반환한다.

### WAS의 종류

tomcat vs undertow vs netty
undertow
NON-Blocking API와 Bloking API 모두 지원한다.
WAS = 웹서버 + 서블릿 컨테이너.


## 8. httpd
httpd는 웹 서버의 백그라운드에서 실행되어, 들어오는 서버 요청을 대기하는 소프트웨어 프로그램이다. 이 데몬은 자동으로 요청에 응답하며 HTTP를 사용하여 인터넷을 경유, 하이퍼텍스트, 멀티미디어 문서들을 서비스한다.

## 9. docker, docker-compose, 쿠버네티스

### 도커의 정의


도커의 장점
1. 획일화된 쉽고 빠른 실행 환경 구축
실행환경이 다른 것은 운영되고 있는 서비스에게는 큰 문제가 될 수 있다. 예를 들어 로컬환경과 운영환경이 다른 경우다.
2. 이미지를 통해 환경을 공유할 수 있다.
도커 허브를 통해 다른 개발자들이 구성해둔 개발 환경들을 내려받을 수 있다.
3. 쉬운 배포
파일 반영이 아닌 도커 이미지를 배포하면 되기 때문에 훨씬 좋다.

컨테이너는 애플리케이션을 환경에 구애 받지 않고 실행한느 기술.
-> 예를 들어서 깃랩을 우분투 서버에 올릴때나 센트OS에 올릴때 사용되는 명령어가 다르다. 즉 환경에 어플리케이션이 영향을 받고 있다는 의미.



한번에 여러 개의 docker 들을 관리하는 툴 같다.

Docker Compose 는 간단하게 여러 Docker application 들을 어떻게 실행할지 정의하고 실행할 수 있는 툴입니다

이렇게 local 환경 관리에 Docker Compose 를 이용했을 때 어떤 장점들이 있을까요?

띄우고 내리는 등의 행위가 편하다
Docker 환경이 파일로 관리된다
협업 하는 모두가 명령어 하나로 쉽게 같은 환경을 사용할 수 있게된다

도커는 ‘이미지를 만들고 컨테이너에 띄우는 도구’이고 쿠버네티스는 ‘도커를 관리하는 툴’이다.

도커라는 것은 컨테이너 기반으로 서비스를 운영할 수 있도록 하는 것.
도커의 장점?

쿠버네티스가 가지는 역할

## 9. SQL vs NoSQL

읽기 처리를 자주하지만 데이터를 자주 변경하지 않는경우 nosql이 더 낫다..?

RDB는 스키마가 엄격하다. 스키마에 맞지않는 데이터는 추가할 수 없다.
RDB의 장점은 명확한 구조를 가지기 때문에 즉 엄격한 스키마를 따르기 때문에 테이블에서 데이터의 중복이 발생하지 않으며 (사실 발생하지 않는 구조로 정규화 시켜야 한다. 발생하지 않음을 강제하진 않는다. 단지 그걸 추구할 뿐)
데이터의 정합성을 유지하는 것에 포커스를 가진다. 다른 테이블에서 부정확한 데이터를 다룰 위험이 없다.

No-sql

 SQL 세상에서는 정해진 스키마를 따르지 않는다면 데이터를 추가 할 수 없지만, NoSQL에서는 다른 구조의 데이터를 같은 컬렉션(= SQL에서의 테이블)에 추가할 수 있습니다. 이게 핵심적인 차이인듯

 컬렉션 == 테이블
 다큐먼트 == 로우

 SQL 관점에서 여러 테이블이 조인된 형태로 한 다큐먼트에 저장된다. 그렇기 때문에 실제로 NoSQL 데이터 베이스에는 조인의 개념이 존재하지 않는다.

조인을 하지 않기 때문에 -> 관계를 기준으로 데이터들을 찾는 작업이 없기 때문에 RDB 보다 빠른 것이다.
그러나 데이터의 정합성을 보장하지 않는다.

이런 방식은 데이터가 중복되기 때문에 불안정한 측면이 있습니다. 실수로 컬렉션 B에서는 데이터를 수정하지 않았는데, 컬렉션 A에서만 데이터를 업데이트 할 위험이 있습니다. -> 데이터가 중복되기때문에 발생하는 오류들이 많다.

RDB 에서는 이런 문제가 발생하지 않도록 정규화를 하는데 NoSQL은 이게 없나보다.

## 10. 수직적 확장 & 수평적 확장

수직적 확장 -> 단순히 데이터베이스 서버의 성능을 향상시키는 것.
수평적 확장 -> 더 많은 서버가 추가되고 데이터베이스가 전체적으로 분산됨을 의미.

SQL 데이터베이스는 데이터가 저장되는 엄격한 스키마 때문에 수직적 확장만이 가능. 여러 대의 데이터베이스를 가지기가 어렵다.


그럼에도 불구하고, 이러한 방식의 커다란 장점은 복잡하고 (어떤 순간에는 느린) 조인을 사용할 필요가 없다는 것입니다. 

SQL의 장점
명확하게 정의 된 스키마, 데이터 무결성 보장
관계는 각 데이터를 중복없이 한번만 저장됩니다.

NoSQL의 장점
스키마가 없기때문에, 훨씬 더 유연합니다. 즉, 언제든지 저장된 데이터를 조정하고 새로운 "필드"를 추가 할 수 있습니다.
데이터는 애플리케이션이 필요로 하는 형식으로 저장됩니다. 이렇게 하면 데이터를 읽어오는 속도가 빨라집니다.
수직 및 수평 확장이 가능하므로 데이터베이스가 애플리케이션에서 발생시키는 모든 읽기 / 쓰기 요청을 처리 할 수 있습니다.

그리고 단점은 아래와 같습니다.

SQL의 단점
상대적으로 덜 유연합니다. 데이터 스키마는 사전에 계획되고 알려져야 합니다. (나중에 수정하기가 번거롭거나 불가능 할 수 도 있습니다.)
관계를 맺고 있기 때문에, JOIN문이 많은 매우 복잡한 쿼리가 만들어 질 수 있습니다.
수평적 확장이 어렵고, 대체로 수직적 확장만 가능합니다. 즉 어떤 시점에서 (처리 할 수 있는 처리량과 관련하여) 성장 한계에 직면하게 됩니다.

NoSQL의 단점

유연성 때문에, 데이터 구조 결정을 하지 못하고 미루게 될 수 있습니다.
데이터 중복은 여러 컬렉션과 문서가 (SQL 세계에서 처럼 하나의 테이블에 하나의 레코드가 아니라) 여러 개의 레코드가 변경된 경우 업데이트를 해야 합니다.
데이터가 여러 컬렉션에 중복되어 있기 때문에, 수정(update)를 해야 하는 경우 모든 컬렉션에서 수행해야 함을 의미합니다. (SQL 세계에서는 중복된 데이터가 없기 때문에 한번만 수행하면 됩니다.)

## 11. mongodb vs redis

redis 는 인 메모리 데이터 구조 저장소. 그러면 이건 디스크에는 저장을 못하나?

Redis는 휘발성 메모리, 즉 RAM에 키-값 쌍으로 데이터를 저장하는 메모리 내 데이터 저장소이며 매우 빠릅니다.
MongoDB 데이터는 디스크에 저장됩니다

Redis는 효율적인 캐시 메커니즘으로 작동하지만 데이터베이스로 redis를 선택 하려면 추가 오버 헤드가 필요합니다. -> 레디스는 전체적인 저장소로 사용하기에는 무리가 있고, 캐싱의 목적으로 쓰는게 맞다고 본다
메모리도 제한되고. 성능을 위해 많은 것들을 포기한 케이스.

Spring의 세션 클러스터링은 기본적으로 Redis를 이용하여 진행됩니다.

NoSQL은 RDBMS에 비해 속도와 확장성이 뛰어납니다. 위 문서를 통해 MySQL과 같은 RDBMS는 속도가 중요한 캐싱에는 적합하지 않다는 것을 알 수 있었습니다.

## 12. Redis, Memcached

Redis는 다양한 데이터 타입을 지원, Memcached 는 String만 지원.
Redis는 디스크에 백업 데이터를 저장.

## 13. ELK (Elasticsearch, Logstash, Kibana)

Elasticsearch 는 JSON 기반의 분산형 오픈 소스 RESTful 검색 엔진. 예전에 먼가 Redis 처럼 저장소로 생각했는데 그게 아니고 단순히 검색엔진.

그러면 데이터는 어디에 저장이 되어 있는 거지? 내부에 자체적으로 저장소를 가지는 거 같다.

ES는 JVM위에서 구동되기 때문에 JDK를 설치해야 합니다. 자바로 구현되어 있다. 1.8 이상의 버전을 활용해야 한다.


Elasticsearch 용어

Database = Index
Table = Type
Row = Document
Column = Field
Index = Analyze
Primary Key = _id
Schema = Mapping
Physical partition = Shard
Local Partition = Route
SQL = Query DSL

클러스터 - elasticsearch 에서 가장 큰 시스템 단위를 의미. 최소 하나 이상의 노드로 이루어짐. 클러스터간 데이터 접근,교환이 불가능.

인덱스 - RDBMS에서 데이터베이스에 대응되는 개념.

샤드 - 데이터를 분산해서 저장하는 방법 (파티션 같은 느낌). 스케일 아웃을 위해서 index를 여러 shard로 쪼갠 것.

elasticsearch 특징

scale out - 샤드를 통해서 규모가 수평적으로 늘어날 수 있다.

schema free - json 문서를 통해 데이터 검색을 수행함으로 스키마 개념이 없다.

restful - 데이터 CRUD 작업은 HTTP Method 에 맞춰서 수행된다.

elasticsearch가 강점을 보이는 부분은 문장이나 여러 단어들의 조합이 저장될 때이다. 문장은 여러 단어들로 구성이 되어있고 그 중 중요한 키워도 있고 큰 의미가 없는 단어들도 있다. elasticsearch는 데이터를 저장할 때 의미있는 단어들을 추출해 해당 단어들로 inverted index를 생성한다.

elasticsearch는 수많은 analyzer와 tokenizer가 존재하는데 이를 잘 활용해야 elasticsearch를 제대로 활용한다 볼 수 있다.

#### Logstash

로그 수집 파이프라인 -> Logstash

## 운영체제 - 파이프라인
차를 만들떄 분업을 하는데 차체를 만들고,안에 엔진을 만들고, 도색을하고 여러 단계를 거치지.

근데 차를 만들어달라는 요구가 들어옴.
5단계의 업무들이 차 한대에 대해서 집중을함. 그래서 만약에 1단계에서 업무를 하고있으면 다른 단계들이 idle 상태이다. 놀고있다는 의미. 비효율적.

파이프 라인 구조는 다른 단계가 어떤 상태인지는 고려안하고 단지 요구사항 즉 업무가 들어오면 자신의 일을 바로바로 처리하는 구조.

파이프라인 구조.

## pipeline hazard
구조적 해저드. structural hazard
다른 단계에 있는 명령어들이 동시에 같은 자원을 사용하려고 하는 상황 -> 해당 자원을 여러개 설치하는 방법으로 해결.

데이터 해저드. data hazard
앞 명령어 결과를 사용해야 하는데 앞이 아직 끝이 안나서 그 결과를 사용 못하는 상황 -> 파이프라인 지연, 전발전달로 해결


시각화 도구 -> Kibana

## 14. Java Executor


## 15. Spring Framework.

Client에게서 Request이 들어오면. 웹서버를 거치고 WAS로 와서 동적 웹 처리를 위한 Servlet container 영역으로 온다. Servlet container 영역에서 servlet 의 라이프사이클을 관리하는데 Servlet의 구현체인 DispatcherSevlet도 여기서 관리된다.

여기서 Servlet container 는 톰캣 기반 설명임.


Request를 분석하여 매핑된 Controller를 찾는 HandlerMapping 단계를 거치고 있으면 HandlerAdapter 단계에서 Controller를 호출.

Controller에서 view를 return 했을 경우 해당하는 view를 찾아 client에게 return 한다.


## 16. Kafka

## 17. RabbitMQ

## 18. CDN (Content Delivery Network)
원거리에 있는 서버의 컨텐츠를 매번 네트워크 상으로 데이터를 받는 것은 성능적인 문제가 있기 때문에. 보다 가깐 곳에 프록시 서버를 두고 캐싱하는 방법을 말하는 것 같음.

CDN은 콘텐츠에 대한 요청이 발생하면 사용자와 가장 가까운 위치에 존재하는 서버로 매핑시켜, 요청된 파일의 캐싱된(사전 저장된) 버전으로 요청을 처리합니다

인터넷 트래픽의 절반 이상이 CDN(콘텐츠 전송 네트워크)을 통해 전송됩니다. CDN의 목표는 웹 페이지에 대한 요청이 이동해야 하는 물리적 거리를 줄여 요청 제출 시간과 장치에 완전히 로딩되는 웹 페이지 간의 지연 시간을 줄이는 것입니다.

기본적으로 전세계적으로 인터넷을 연결시켜주는 가장 큰 매체는 해저케이블.


## 19. CORS

## 20. RESTful API

Resource State Transfer API

Resource 중심으로 API를 설계한다.

서버에게 Resource 들은 다양하게 있지만 여기서는 주로 모델, 도메인을 의미.

API를 설계할때 도메인을 중심으로 설계한다는 것.

도메인을 조작할 수 있는 CRUD API 를 Http Method에 따라 제공

URI를 활용하여 Resource를 표현.

Open API 가 주로 RESTful API 를 사용.

RESTful API 의 장점 : 클라이언트가 없어도 API를 설계할 수 있따. - 즉 범용적으로 모든 클라이언트들에게 제공 가능한 API를 만듬.
특정 클라이언트를 위한 API 가 아니기 때문에 한 클라이언트에게 맞춰진 API를 만들 수는 없지만 매번 API 개발 요청이 들어왔을 때
새롭게 만들지 않아도 됨.

A B C 도메인이 있을 때 RESTful API는 A 를 조작하기 위한 CRUD API, B, c 모두 제공


## 21. 함수형 프로그래밍.

### 일급 함수.

변수나 데이터 구조안에 담을 수 있다.
파라미터로 전달할 수 있다.
반환값으로 사용할 수 있다.

전통적인 자바 언어 진영에서 함수형 프로그래밍은 사실 조금은 낯설다. 기본적으로 OOP를 위해 만들어졌기 때문.
그 사유로 자바에서는 함수가 클래스 없이 만들수가 없다.

java8 이후에 람다, 메소드 참조 문법이 생겨나면서 함수형 프로그래밍이 보편화되기 시작.

함수형 프로그래밍이란. 함수를 일급변수로 볼수 있다는 것.
풀어서 설명하자면. 함수를 값처럼 변수에 저장하고 사용할 수 있다.

함수는 값과 다르게 데이터 그 자체가 아닌 어떠한 처리 동작, 일련의 순서를 표현하는데 이걸 변수에 저장할 수 있다는 의미.
함수형 프로그래밍을 활용하면 기존에는 OOP에서 다형성을 활용해서 해결하던 문제들을 FP 방식으로 보다 심플하게 해결할 수 있음.

예를 들어

항공사 벤더가 다양하게 있고. 이 벤더들이 공통적으로 상품조회, 결제, 예약 같은 기능을 제공.
개념적으로는 동일하지만 실제 구현되는 내용은 다름.

이럴때 OOP는 상품조회, 결제 등을 표준으로 정의하는 interface를 생성하고. 이를 규격으로 각 항공사 벤더들이 이거에 맞춰서 구현함.

이런 문제를 FP는 항공사마다 다른 이런 구현 방법을 파라미터로 넘겨줄 수 있음.

뭔가 개념적으로 동일하고 실제 구현방법이 다를때. OOP적 해결방법이 있고, FP적 해결 방법이있음.

이둘을 그러면 어떻게 구분해야할까.

뭔가 규모가 크다면 OOP를 활용한 방법이 더 맞다고 봄.
근데 만약 심플하다면 FP로 처리.

### 순수 함수 

그리고 함수형 프로그래밍은 순수함수를 적극 활용함.

순수함수는 기본적으로 데이터의 불변성을 요구함.
부수효과(Side Effect)가 없는 함수. 즉 어떤 함수에 동일한 값을 주었을 때 항상 같은 값을 반환하는 함수.
입력 값에 대한 결과 값이 항상 동일해야 한다.

즉 한 함수 범위 내에서 동작되는 내용들은 파라미터로 제공된 값만을 활용해서 처리되어야 하며 외부에서 받게되는 데이터들을 최대한 자제한다.

실제로 순수함수 형태로 코드를 짜야 테스트 코드를 작성하기도 쉽다.

쓰레드에도 안전하다. 객체에 값을 넣어놓고 함수에서 이를 호출하는 구조로 만들게 되면. 이 객체들은
멀티쓰레드 환경이 되었을 때 각 쓰레드에 의해서 공유되는 데이터가 된다.
그래서 이 데이터가 thread-safe하도록 추가적인 작업이 필요하다.

순수함수 패러다임을 사용할 수 없는 경우는 값을 stateful 해야하는 경우다.
예를 들면 빌더패턴이나 java의 stream 기능같은 것이다.


### 고차함수, 합성함수

이 내용들은 함수를 일급 객체로써 바라볼 수 있기 때문에 나타나는 내용인데.
함수 안에서 함수를 받을 수 있고 그러면서 서로 조합이 가능하다는 부분이다.


## 22. Call By Value Call By Reference

## 23. Stack

세로로된 바구니같은 구조. 밑에있는 데이터들은 위에있는 데이터가 빠져나가야만 빼낼 수 있다.
즉 먼저 넣는 자료가 마지막으로 나오게 되는 First In Last Out (FILO), 선입선출 구조.

### 프로세서 사이클 (메이저 사이클)

CPU가 동작하는 기본적인 원리는 메이저 사이클 혹은 프로세스 사이클 따른다.

명령어 인출 -> 명령어 해독 -> 오퍼랜드 인출 -> 실행 -> 인터럽트 조사

인터럽트가 걸리게 되면 Stack 구조로 구현된 저장소에 이전 프로세스의 메모리 번지를 저장시키고 인터럽트 걸린 프로세스를 시작한다.
이게 해결이 되면 해결된 프로세스는 pop 하고 그 아래에 있는 프로세스가 다시 시작.

스택은 CPU가 명령어들을 수행할 때 가장 기본적으로 사용하는 구조.

## 24. 인터럽트 vs 폴링

지금하고 있는 프로세스보다 더 중요한 프로세스가 등장하게 되면 더 중요한 프로세스를 처리하게 되는데.
이러한 것이 새로운게 기존것을 방해한거로 생각되어 인터럽트 걸렸다라고 표현한다.

각 CPU 인터럽트의 우선순위가 정해져 있음.

인터럽트 벡터 : 인터럽트가 발생했을 때 해야할 일을 정해놓은 것으로 바로 인터럽트 서비스 루틴의 시작 주소. 메모리 번지.

폴링 방법은 계속 대기하는 방법

 "폴링"은 한 프로그램이나 장치에서 다른 프로그램이나 장치들이 어떤 상태에 있는지를 지속적으로 체크하는 전송제어 방식

시스템 내에 동작 중에 폴링 방식과 이벤트 방식이 있다. 폴링 방식은 어떤 상태인지를 주기적으로 확인해보는 것이다. 폴링 방식을 예를 든다면 우편물이 왔는지를 매번 내가 가서 보는 것이다. 이렇게 매번 오가는게 폴링이다. 주기적으로 알아보는 만큼 오지 않았을 때 나가보는 동안 비효율이 발생을 한다.

이벤트 방식은 어떤 상태가 되면 알려주는 것이다. 매번 가는 것이 아니라 우편물이 도착했을 때 문자를 보내는 것이다. 훨씬 효율적일 수 있다. 이벤트 방식로 해당 사람이 오면 알려 주는 방식이다. 두 방식에는 차이가 있지만, 언듯 폴링 방식은 비효율적일 거 같다는 생각을 할 수 있다. 하지만 정기적으로 뭔가를 감시하거나 검사를 해야 한다면 폴링방식도 필요할 것이다. 하지만 이벤트 방식을 통해서 트리거를 발생 시켜서 인지를 하게 되면 그 비효율이 줄어들어서 효율적으로 처리 할 수 있다.

## 25. 큐

가로로 된 통과 같은 구조로 먼저 넣게 되는 자료가 가장 먼저 나오는 First-In First-Out(FIFO) 구조이다.

## 26. 해시

해시 테이블은 key, value 타입의 데이터를 저장하는 자료구조.

key 값을 해시함수로 생성하는데 이 key 값이 해시테이블 크기만큼 우선 고유하게 만든다.
만약 데이터가 이 해시테이블보다 많다면 이 key 값이 중복될 수도 있다.

해시값이 중복된 경우 연결리스트 구조로 데이터가 저장이 되며 그 안에서 탐색을 한다.
해시테이블보다 데이터 양이 작다면 시간복잡도는 O(1) 이 되며.
시간 복잡도를 공간복잡도로 바꾼 형태라고 볼 수 있다.

해시 값을 생성할때 중요한 포인트는 해시코드가 골고루 분포할 수 있도록 하는게 중요하다.
해시코드가 특정 코드에 집중되있다면 해시테이블의 기능을 효과적으로 이용할 수 없다.

## 27. 리스트

### 배열리스트

데이터를 추가/삭제하는데에는 배열리스트가 데이터를 밀고 당기고 해야하기 떄문에 추가적인 연산작업이 있어 오래걸린다.

데이터를 검색할 때에는 단순히 해당 번지를 조회하면 되기 때문에 연결리스트 보다 빠르다.

### 연결리스트

데이터를 추가/삭제할 때 노드가 가리키는 대상만 바꿔주면 되어 배열리스트에 비해 빠르다.

데이터를 검색할 때에는 순차접근만 가능하기 때문에 느리다.

## 28. 우선순위 큐

기본적으로 큐는 FIFO 구조로 먼저 들어간 데이터가 먼저 나와야 한다.

우선순위 큐는 기본적으로 큐 형태지만. 우선순위를 고려하고. 우선순위가 더 높은 값이 있다면 그 데이터를 먼저 처리한다.

보통 우선순위 큐를 구현하기 위해서 힙 구조를 활용한다.

삽입: 데이터가 들어오면 각 노드별로 들어온 데이터가 크거나 작은지를 비교하고 정책에 따라서 크면 왼쪽 노드로 작으면 오른쪽 노드로 진행된다.


## 29. 힙

최댓값 또는 최솟값을 찾아내는 연산을 쉽게 하기 위해 고안된 구조로, 각 노드의 값이 우선순위가 자식노드 보다 높은 구조다.

모든 노드에 저장된 값(우선순위)들은 자식 노드들의 것보다 (우선순위가) 크거나 같다.

따라서 힙은 루트 노드에 우선순위가 가장 높은 데이터를 위치시키는 구조가 됨.

삽입 : 새로들어오는 데이터를 우선순위가 가장 낮다고 가정하고 가장 단말 노드에 추가한다. 그 후에 부모노드와 값을 비교하면서
우선순위가 맞게 될때까지 반복. 새로 들어온 값의 우선순위가 부모보다 낮으면 끝.

삭제 : 루트노드가 제거되고 난 후. 가장 우선순위가 낮은 데이터를 루트노드로 옮긴다. 그리고 자식노드들과 우선순위를 비교하면서 swap

## 31. ARP (Address Resolution Protocol)

Data Link 계층에서 각 함소들끼리 데이터를 주고받고 연결하는 기준은 바로 맥어드레스.
이 맥어드레스는 NIC (Network Interface Card) 가 고유하게 가지고 있따.

IP로 실제로 통신하는게 아니고 맥어드레스를 기준으로 통신을 함. 그렇기 때문에
IP를 맥어드레스로 바꿔주는 과정이 필요한데 이게 ARP 프로토콜.

맥주소는 기본적으로 48비트

## 32. 패킷

데이터를 통신망을 통해 전송하기 쉽도록 자른 데이터 전송 단위.

## 33. 경력기간동안 진행한 업무를 어필

### 신규 항공사 API 연동 서버 구축.

OTA(Online Travel Agency) 서비스를 하는 부서에서 업무를 함 여기서 주요 상품들은 항공권인데,
실시간 항공권 예매 시스템에서 가져야할 대표적인 기능들이 상품조회, 예약, 발권, 결제, 취소 정도가 있음.
이거가 항공사 벤더마다 다른 형태로 구현이 되어있어서 이를 하나의 인터페이스로 추상화, 표준화를 하고 클라이언트가 항공사 벤더를 신경쓰지 않고 추상화된 규격을 기준으로 비지니스 로직을 작성할 수 있도록 하였음.

기존 API 서버는 항공사 상품조회 연동을 실시간적으로 가져오도록 구현되어 있었음. 항공사가 총 8곳, 평균적으로 항공상품을 가져오는데 3~4초 정도 소요가 되었는데. 매번 연동하는 방식보다. 레디스 캐쉬 서버를 두고. 클라이언트들은 이곳에서 스케줄 정보를 가져올 수 있도록 하고. 레디스 캐쉬 서버에서 각 항공사에 주기적으로 상품조회를 함.

## 34. TCP vs UDP

OSI 7Layer 중 4계층에서 많이 사용되는 두 프로토콜.

TCP
Streaming 서비스에 불리하다. (손실된 경우 재전송 요청을 하므로)

## GC

### Stop-The-World
GC를 실행하기 위해서 JVM이 그 위에서 동작하는 어플리케이션의 실행을 멈추는 것.

top-the-world가 발생하면 GC를 실행하는 쓰레드를 제외한 나머지 쓰레드는 모두 작업을 멈춘다

대개의 경우 GC 튜닝이란 이 stop-the-world 시간을 줄이는 것이다.

gc는 말그대로 Garbage Collection을 수행하여 불필요한 Obejct를 Memory 상에서 제거하는 것을 의미합니다.

System.gc() 가 안좋은 이유. -> 이건 내 판단이데. System.GC() 함수는 FullGC 를 호출하는데. 보통 GC가 처리하는 쓰레기들은
young 영역에서 끝이난다. 하지만 이함수는 fullGc 까지 호출하고 그러면 stop the world 를 하기때문에 성능에 무리가 간다.

JVM의 구성인 Young 영역, Old 영역

모든 객체가 쓰레기인지 검사하는 무식한 방식의 가비지 컬렉션은 규모가 큰 프로그램에서 심각한 문제가 생길 수 있다.

JVM GC 설계자들은 경험적으로 대부분의 객체가 생겨나자마자 쓰레기가 된다는 것을 알고 있었다.

이것을 '약한 세대 가설(weak generational hypothesis)'이라 부른다.
따라서 매번 전체를 검사하지 않고 일부만 검사할 수 있도록 generational한 구조를 고안해 내었다.

young generation
객체 대부분이 생성될 때 이곳으로 들어간다.
이곳이 가득차면 minor gc가 발생한다.

minor gc가 발생하면 살아있는 객체들만 체크하고 나머지는 다 없애버린다.
살아남은 객체들 중 더 오래 쓸 것 같은 것들은 tenured generation으로 옮긴다.

tenured generation
이곳이 가득 차면 major gc가 발생한다.
major gc는 minor gc보다 더 오래 걸린다.


Young 영역(Yong Generation 영역): 새롭게 생성한 객체의 대부분이 여기에 위치한다. 대부분의 객체가 금방 접근 불가능 상태가 되기 때문에 매우 많은 객체가 Young 영역에 생성되었다가 사라진다. 이 영역에서 객체가 사라질때 Minor GC가 발생한다고 말한다.

Young 영역은 다시 3가지로 나뉨.
Eden 영역
Survivor 영역 2개 - 서로 계속 스왑함.
Eden -> Survivor로 가며, Survivor에서도 계속 살아나면 old 영역으로 간다.

Old 영역(Old Generation 영역): 접근 불가능 상태로 되지 않아 Young 영역에서 살아남은 객체가 여기로 복사된다. 대부분 Young 영역보다 크게 할당하며, 크기가 큰 만큼 Young 영역보다 GC는 적게 발생한다. 이 영역에서 객체가 사라질 때 Major GC(혹은 Full GC)가 발생한다고 말한다.

Old 영역은 기본적으로 데이터가 가득 차면 GC를 실행한다.

Serial GC - Serial GC는 데스크톱의 CPU 코어가 하나만 있을 때 사용하기 위해서 만든 방식이다. Serial GC를 사용하면 애플리케이션의 성능이 많이 떨어진다.

Parallel GC - Parallel GC는 Serial GC와 기본적인 알고리즘은 같지다. 그러나 Serial GC는 GC를 처리하는 스레드가 하나인 것에 비해, Parallel GC는 GC를 처리하는 쓰레드가 여러 개이다. 그렇기 때문에 Serial GC보다 빠른게 객체를 처리할 수 있다. Parallel GC는 메모리가 충분하고 코어의 개수가 많을 때 유리하다. Parallel GC는 Throughput GC라고도 부른다.

Parallel Old GC(Parallel Compacting GC)
Concurrent Mark & Sweep GC(이하 CMS)
G1(Garbage First) GC

## JVM

### JVM의 목적 

자바 가상 머신으로 자바 바이트 코드를 실행할 수 있는 주체다. (Class 파일이 바이트 코드로 작성되어 있다.)

CPU나 운영체제(플랫폼)의 종류와 무관하게 실행이 가능하다.

즉 운영체제 위에서 동작하는 프로세스로 자바 코드를 컴파일해서 얻은 바이트 코드를 해당 운영체제가 이해할 수 있는 기계어로 바꿔 실행시켜주는 역할.

### JVM의 구성

Class Loader, Execution Engine, Garbage Collector, Runtime Data Area

1. Class Loader

자바에서 소스를 작성하면 Person.java 처럼 .java파일이 생성된다.

.java 소스를 자바컴파일러가 컴파일하면 Person.class 같은 .class파일(바이트코드)이 생성된다.

이렇게 생성된 클래스파일들을 엮어서 JVM이 운영체제로부터 할당받은 메모리영역인 Runtime Data Area로 적재하는 역할을 Class Loader가 한다. (자바 애플리케이션이 실행중일 때 이런 작업이 수행된다.)

2. Execution Engine

Class Loader에 의해 메모리에 적재된 클래스(바이트 코드)들을 기계어로 변경해 명령어 단위로 실행하는 역할을 한다.

명령어를 하나 하나 실행하는 인터프리터(Interpreter)방식이 있고 JIT(Just-In-Time) 컴파일러를 이용하는 방식이 있다.

JIT 컴파일러는 적절한 시간에 전체 바이트 코드를 네이티브 코드로 변경해서 Execution Engine이 네이티브로 컴파일된 코드를 실행하는 것으로 성능을 높이는 방식이다.

자바는 왜 자바 컴파일러로 바이트 코드를 생성하고 또 그 이후해 자바 인터프리터를 활용해서 기계어로 번역하는가.

자바를 활용하면 C 언어와 같이 완벽하게 기계어로 매핑된 컴파일이 불가능하다.
왜냐하면 플랫폼에 종속적이지 않기 떄문이다.

왜 자바는 기본적으로 컴파일과 인터프리트를 병행 하는 것 일까?

바로 기계어로 변환하는 컴파일러의 경우는 프로그램이 작성된 기계상에서실행할 때 매우 효율적으로 실행된다. 이는 대부분의 하드웨어 제어 시스템의 프로그래밍언어가 C인 이유이다. 그러나 이와 동시에 기계 종류에 종속된다는 말이기도 하다. 자바 인터프리팅은 자바 컴파일러를 통해 생성된 클래스파일을 기계어로 변환한다.

JIT 컴파일(just-in-time compilation) 또는 동적 번역(dynamic translation)은 프로그램을 실제 실행하는 시점에 기계어로 번역하는 컴파일 기법이다.

전통적인 입장에서 컴퓨터 프로그램을 만드는 방법은 두 가지가 있는데, 인터프리트 방식과 정적 컴파일 방식으로 나눌 수 있다. 이 중 인터프리트 방식은 실행 중 프로그래밍 언어를 읽어가면서 해당 기능에 대응하는 기계어 코드를 실행하며, 반면 정적 컴파일은 실행하기 전에 프로그램 코드를 기계어로 번역한다.

JIT 컴파일러는 두 가지의 방식을 혼합한 방식으로 생각할 수 있는데, 실행 시점에서 인터프리트 방식으로 기계어 코드를 생성하면서 그 코드를 캐싱하여, 같은 함수가 여러 번 불릴 때 매번 기계어 코드를 생성하는 것을 방지한다.

3. Garbage Collector

Garbage Collector(GC)는 Heap 메모리 영역에 생성(적재)된 객체들 중에 참조되지 않는 객체들을 탐색 후 제거하는 역할을 한다.

GC가 역할을 하는 시간은 정확히 언제인지를 알 수 없다. (참조가 없어지자마자 해제되는 것을 보장하지 않음)

또 다른 특징은 GC가 수행되는 동안 GC를 수행하는 쓰레드가 아닌 다른 모든 쓰레드가 일시정지된다.

특히 Full GC가 일어나서 수 초간 모든 쓰레드가 정지한다면 장애로 이어지는 치명적인 문제가 생길 수 있는 것이다. (GC와 관련된 내용은 아래 Heap영역 메모리를 설명할 때 더 자세히 알아본다.)

4. Runtime Data Area

JVM의 메모리 영역으로 자바 애플리케이션을 실행할 때 사용되는 데이터들을 적재하는 영역이다.

이 영역은 크게 Method Area, Heap Area, Stack Area, PC Register, Native Method Stack로 나눌 수 있다.

1. Method area (메소드 영역)

클래스 멤버 변수의 이름, 데이터 타입, 접근 제어자 정보같은 필드 정보와 메소드의 이름, 리턴 타입, 파라미터, 접근 제어자 정보같은 메소드 정보, Type정보(Interface인지 class인지), Constant Pool(상수 풀 : 문자 상수, 타입, 필드, 객체 참조가 저장됨), static 변수, final class 변수등이 생성되는 영역이다.

2. Heap area (힙 영역)

new 키워드로 생성된 객체와 배열이 생성되는 영역이다.
메소드 영역에 로드된 클래스만 생성이 가능하고 Garbage Collector가 참조되지 않는 메모리를 확인하고 제거하는 영역이다.

3. Stack area (스택 영역)

지역 변수, 파라미터, 리턴 값, 연산에 사용되는 임시 값등이 생성되는 영역이다.

int a = 10; 이라는 소스를 작성했다면 정수값이 할당될 수 있는 메모리공간을 a라고 잡아두고 그 메모리 영역에 값이 10이 들어간다. 즉, 스택에 메모리에 이름이 a라고 붙여주고 값이 10인 메모리 공간을 만든다.

클래스 Person p = new Person(); 이라는 소스를 작성했다면 Person p는 스택 영역에 생성되고 new로 생성된 Person 클래스의 인스턴스는 힙 영역에 생성된다.

4. PC Register (PC 레지스터)

Thread(쓰레드)가 생성될 때마다 생성되는 영역으로 Program Counter 즉, 현재 쓰레드가 실행되는 부분의 주소와 명령을 저장하고 있는 영역이다. (*CPU의 레지스터와 다름)

이것을 이용해서 쓰레드를 돌아가면서 수행할 수 있게 한다.

5. Native method stack

자바 외 언어로 작성된 네이티브 코드를 위한 메모리 영역이다.

보통 C/C++등의 코드를 수행하기 위한 스택이다. (JNI)



1,2번인 메소드 영역과 힙 영역을 모든 쓰레드가 공유하고,

3,4,5번인 스택 영역과 PC 레지스터, Native method stack은 각각의 쓰레드마다 생성되고 공유되지 않는다.

## default 메소드

## Spring AOP
AOP 는 OOP 설계론이 가지는 단점을 커버하기 위해 생겨난 방법.

객체 중심으로 디자인하기 때문에. 모든 객체들이 가지는 공통 속성에 대해서 중복이 일어난다.

## Spring IOC
IoC란 말 그대로 제어의 역전. 즉 제어권이 바뀌었다는 것.
개발자가 객체의 생성, 의존성 관리를 직접하는게 아니고 프레임워크, 컨테이너에서 대신 해준다는 의미.

이로 인해 개발자가 직접 객체를 관리해야하는 코드들을 줄일 수 있다

## Spring DL (Dependency Lookup)
Dependency Lookup - 의존대서을 검색을 통해 반환받는 방식
ex) factory.getBean(id);

DL은 의존성 검색이다. 이는 빈에 접근하기 위해 컨테이너가 제공하는 API를 이용하여 Bean을 Lookup하는 것이다.

## Spring DI (Dependency Injection)
DI는 의존성 주입. 이는 각 클래스 간에 의존성을 자신이 아닌 외부에서 주입하는 개념.

의존성 주입을 사용하게 되면 객체 주입을 외부에서 하기 때문에 보다 유연한 코드를 작성할 수 있다.

## TDD (Test Driven Development)

테스트 주도 개발은 매우 짧은 개발 사이클을 반복하는 소프트웨어 개발 프로세스 중 하나이다. 개발자는 먼저 요구사항을 검증하는 자동화된 테스트 케이스를 작성한다. 그런 후에, 그 테스트 케이스를 통과하기 위한 최소한의 코드를 생성한다. 마지막으로 작성한 코드를 표준에 맞도록 리팩토링한다. 이 기법을 개발했더나 '재발견' 한 것으로 인정되는 켄트 백은 2003년에 TDD가 단순한 설계를 장려하고 자신감을 불어넣어준다고 말한다.

## 테스트

유닛테스트 : 함수 하나하나와 같이 코드의 작은 부분을 테스트 하는 것.

또한, 유닛 테스트는 매우 간단하고 명확하여야 한다.

기본적으로 테스트를 위한 입력 값을 주어서 그에 대한 함수의 출력 값이 정확 한지 아닌지를 판단하는 것이 유닛 테스트라 할 수 있다.

코드의 설계가 별로 좋지 못하다면 유닛 테스트를 작성하기도 어려워진다.

비유하자면, 유닛 테스트는 척추에 비유할 수 있다.

유닛 테스트를 사용한다면 좋은 코드를 디자인할 수 있을 뿐만 아니라 어떤 함수(메소드)에 변화가 생겼을 때 그 함수가 안전하게 수행되는지를 보장해주고 같은 함수(메소드)를 다른 종류의 테스트에서도 적용하기 쉽게 만들어 준다.

따라서 함수(메소드) 하나하나 테스트 코드를 작성하는 유닛 테스트는 좀 더 나은 코드를 만들 수 있도록 도와준다.

통합 테스트 : 서로 다른 시스템들의 상호작용이 잘 이루어 지는지 테스트하는 것.

기능 테스트 : 사용자와 어플리케이션의 상호작용이 원활하게 이루어지는지 테스트하는 것.

## mod_jk

## 캐시

시간적 지역성
한번 액세스한 메모리는 가까운 미래에 다시 액세스할 가능성이 높다.

공간적 지역성
한번 액세스한 메모리 주변은 가까운 미래에 액세스할 가능성이 높다.

## 데이터베이스 인덱스
B+ Tree 구조로 별도의 인덱스 테이블을 만듬.

## shell script

스크립트는 일반적으로 인터럽트 방식으로 동작하는 프로그램. 즉 프로그램의 한 라인씩 읽어 해석하고 실행하는 과정을 반복하도록 만들어진 프로그램.

쉘이라는 것은 운영체제에서 제공하는 커널 들에 접근할 수 있는 방법. 대화형 형태로 운영체제에서 제공하는 시스템 명령어들을 사용자가 사용할 수 있도록 한다.

쉘 명령어들을 일련의 순서대로 작성하면 쉘 스크립트가 되며. 인터프리터가 순서대로 해석하고 실행한다.

쉘 프로그램도 여러 종류가 있는데 

/bin/sh
/bin/bash (bourne-again shell)
/bin/csh
/bin/ksh
/bin/tcsh

여기서 bash 가 현재 리눅스의 표준 쉘이다. 윈도우에서 사용하는 cmd의 명령어와 리눅스에서의 명령어가 다른 것은 알고 있을 텐데 각 운영체제에 구현된 커널이 다른 것이 영향이 있겠지만 쉘(명령어 해석기, 대화형 프로그램)이 다르기 때문이다.



## 컴파일러와 인터프리터

## bash

## 프로그램 카운터 (PC)

마이크로프로세서 내부에 있는 레지스터 중 하나로서, 다음에 실행될 명령어의 주소를 가지고 있어 실행할 기계어 코드의 위치를 지정한다.

프로그램 카운터는 각 명령 주기에 따라서 자동으로 증가되며, 메모리에 있는 명령어들이 순차적으로 실행될 수 있도록 한다.

단 분기 또는 서브루틴 호출/복귀 등의 명령어는 프로그램 카운터에 실행해야할 위치가 바로 다음 코드가 아니라 새로운 기계어 코드의 위치 값이 들어간다.

## 배치 프로그램

일괄처리(batch processing)란 컴퓨터 프로그램 흐름에 따라 순차적으로 자료를 처리하는 방식.

개별적으로 어떤 요청이 있을 때마다 실시간으로 통신하는 것이 아니고. 한꺼번에 일괄적으로 대량 건을 처리하는 방법. 특히 배치는 보통 정해진 특정한 시간에 실행된다.

1. 대량 건의 데이터를 처리.
2. 틀정 시간에 실행.
3. 일괄적으로 처리.

